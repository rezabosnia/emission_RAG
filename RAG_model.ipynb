{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143b2b63-ba43-4334-ba36-1d7e7cd08cdd",
   "metadata": {},
   "source": [
    "# Emission RAG Architecture Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29cb111-db00-425b-8857-f7317ea4a56e",
   "metadata": {},
   "source": [
    "## Install Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab83fd94-abd4-477d-8fde-f3ac9d7b95fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentence-transformers\n",
    "pip install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929603b3-89a3-4e88-9454-6ff7962118a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b3808-277e-49e6-9d92-5f02a433700e",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f79d42-a789-4564-b85c-b927d2cdc703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53fab1e-8b05-4d6b-b351-e4eae616b1bb",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb80f6c-08e1-4e74-87b2-e44dd664b941",
   "metadata": {},
   "source": [
    "### Import downloaded carbon emission data in csv format, upload to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f251e8-23ef-4490-ad82-4732c4096ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('owid-co2-data.csv')\n",
    "\n",
    "#filter only the latest data\n",
    "filtered_df = df[df['year'] > 2000]\n",
    "filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e9fa10-48a2-4b0f-a0a7-4ad8d4b2cc85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c8d6e-b68f-4479-9b9a-564ce31cd555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import config  # Import the config file\n",
    "\n",
    "# Set environment variables using values from config.py\n",
    "os.environ[\"POSTGRES_HOST\"] = config.POSTGRES_HOST\n",
    "os.environ[\"POSTGRES_DB\"] = config.POSTGRES_DB\n",
    "os.environ[\"POSTGRES_USER\"] = config.POSTGRES_USER\n",
    "os.environ[\"POSTGRES_PASSWORD\"] = config.POSTGRES_PASSWORD\n",
    "os.environ[\"POSTGRES_SCHEMA\"] = config.POSTGRES_SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59f81a-80e0-4921-a9a4-28b7a0695a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getenv(\"POSTGRES_HOST\"))  # Should print: your_postgres_host\n",
    "print(os.getenv(\"POSTGRES_DB\"))    # Should print: your_database_name\n",
    "# print(os.getenv(\"POSTGRES_PASSWORD\"))    # You Should never print: passwords or sensitive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f58d4d-2748-4450-b71f-95f61e2aa355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables for PostgreSQL connection\n",
    "POSTGRES_HOST = os.getenv(\"POSTGRES_HOST\", \"localhost\")\n",
    "POSTGRES_DB = os.getenv(\"POSTGRES_DB\", \"postgres\")\n",
    "POSTGRES_USER = os.getenv(\"POSTGRES_USER\", \"postgres\")\n",
    "POSTGRES_PASSWORD = os.getenv(\"POSTGRES_PASSWORD\", \"postgres\")\n",
    "POSTGRES_PORT = os.getenv(\"POSTGRES_PORT\", 5432) # leave at the default port\n",
    "POSTGRES_SCHEMA = os.getenv(\"POSTGRES_SCHEMA\", \"public\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e667bbb-8d3f-4feb-8203-26d227c0a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create PostgreSQL connection string\n",
    "pg_conn_string = f\"postgresql+psycopg2://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "pg_engine = create_engine(pg_conn_string, connect_args={\"options\": f\"-c search_path={POSTGRES_SCHEMA}\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca1b882-7b37-4086-aa4a-56b2c5e1404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_name = POSTGRES_SCHEMA\n",
    "table_name = f\"{schema_name}.example_table_4\"\n",
    "\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "id SERIAL PRIMARY KEY,\n",
    "example_column VARCHAR(255) NOT NULL);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9546b73d-d7d9-481f-908f-bc0dd89657ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_table_query = f\"\"\"\n",
    "DROP TABLE \"carbon_data\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# DROP TABLE \"sales\"\n",
    "# DROP TABLE \"customers\"\n",
    "# DROP TABLE \"products\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372681ca-d21f-420a-aa53-b0dd28020903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=POSTGRES_HOST,\n",
    "        dbname=POSTGRES_DB,\n",
    "        user=POSTGRES_USER ,\n",
    "        password=POSTGRES_PASSWORD,\n",
    "        port=POSTGRES_PORT\n",
    "    )    \n",
    "    print(\"Connection successful!\")\n",
    "    \n",
    "    # Set the schema if required\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SET search_path TO {POSTGRES_SCHEMA};\")\n",
    "        print(f\"Schema set to {POSTGRES_SCHEMA}\")\n",
    "\n",
    "        # cur = conn.cursor()\n",
    "        # cur.execute(create_table_query)\n",
    "        cur.execute(drop_table_query)\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "\n",
    "        print(f\"Table {table_name} created successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error connecting to the database:\", e)\n",
    "finally:\n",
    "    if 'conn' in locals() and conn:\n",
    "        conn.close()\n",
    "        print(\"Connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ff468-3bc2-4e4d-ad14-6a6ffc42758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_engine = create_engine(\"postgresql://muhammad.tribosnia.24@ucl.ac.uk:rzMwmH@uclba-de25v2.cluster-cowglvndjvxv.eu-west-2.rds.amazonaws.com:5432/postgres\")\n",
    "\n",
    "filtered_df.to_sql(\"carbon_data\", pg_engine, schema ='schema_muhammadtribosnia24uclacuk', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cac612-9013-42e8-8d6c-a028b2625baf",
   "metadata": {},
   "source": [
    "### Acess newsdata.io to get latest news, use duckdb to store in in parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd38cb07-bf94-4eb0-be3b-72aa15ed13f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import config  # Import the config file\n",
    "import requests\n",
    "\n",
    "# Set environment variables using values from config.py\n",
    "os.environ[\"API_KEY\"] = config.newsio_api\n",
    "\n",
    "\n",
    "# Environment variables for API connection\n",
    "API_KEY = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da23beaf-f730-4f57-bd3f-f6984b46c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"carbon emissions\"\n",
    "url = f\"https://newsdata.io/api/1/news?apikey={API_KEY}&q={query}&language=en\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    articles = data.get('results', [])[:5]  # Select only the first 5 articles\n",
    "    for i, article in enumerate(articles, start=1):\n",
    "        print(f\"{i}. {article.get('title')}\")\n",
    "        print(f\"   {article.get('link')}\")\n",
    "        print(f\"   Source: {article.get('source_id')} | Published: {article.get('pubDate')}\\n\")\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5bfbb9-73b1-43f5-9033-e35b17840358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the DataFrame\n",
    "results = data['results']\n",
    "df_news = pd.DataFrame([{\n",
    "    'title': item.get('title'),\n",
    "    'description': item.get('description'),\n",
    "    'source': item.get('source_name'),\n",
    "    'country': ', '.join(item.get('country', [])),\n",
    "    'link': item.get('link'),\n",
    "    'pubDate': item.get('pubDate')\n",
    "} for item in results])\n",
    "\n",
    "# Show the first 5 rows\n",
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3643f2fc-742b-4a92-aaa1-a5e813254b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_news = pd.read_csv('news.csv')\n",
    "df_news = df_news.drop(columns=[\"Unnamed: 0\"], errors='ignore')\n",
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f83dbdd-706f-4a4e-bec1-867eaa02b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Save the DataFrame as a Parquet file\n",
    "df_news.to_parquet(\"emission_news.parquet\", index=False)\n",
    "df_news\n",
    "\n",
    "# 2. Connect to (or create) the DuckDB database\n",
    "con = duckdb.connect(\"emission_news_data.duckdb\")\n",
    "\n",
    "# 3. Load the Parquet file into the DuckDB database as a table\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE emission_news AS\n",
    "    SELECT * FROM read_parquet('emission_news.parquet')\n",
    "\"\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd8ac94-9e5c-4d27-bc22-4c9827459259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Verify the data\n",
    "con.execute(\"SELECT * FROM emission_news LIMIT 5\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ce4331-e059-40cc-9a24-9465b5706e8d",
   "metadata": {},
   "source": [
    "## Creating RAG Summary and Sentence Embeddings Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1f39f8-cb19-4091-976a-b3a5e3d771ae",
   "metadata": {},
   "source": [
    "### Download carbon data files from postgres and emission-related news from duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd60a7a5-a4f4-4958-96c0-599f90efb5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###carbon data\n",
    "from sqlalchemy import text\n",
    "pg_engine = create_engine(\"postgresql://muhammad.tribosnia.24@ucl.ac.uk:rzMwmH@uclba-de25v2.cluster-cowglvndjvxv.eu-west-2.rds.amazonaws.com:5432/postgres\")\n",
    "\n",
    "query = text(\"SELECT * FROM schema_muhammadtribosnia24uclacuk.carbon_data;\")\n",
    "# sales_data = pd.read_sql_query(query, conn)\n",
    "df = pd.read_sql_query(query, pg_engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d80819-a61f-4e7a-ab06-0fa86bcacf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "###emission-related news\n",
    "df_news = con.execute(\"SELECT * FROM emission_news\").fetchdf()\n",
    "df_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac652a08-0f7a-472b-b15f-e8a952b71f5d",
   "metadata": {},
   "source": [
    "### Turn dataframe into RAG Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a254b485-732c-49a2-948e-9755cfb3e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rag_summary using all columns\n",
    "df['rag_summary'] = df.apply(lambda row: (\n",
    "    \"[TYPE: CARBON DATA]\\n\"\n",
    "    \"Document: Full Carbon Data Entry\\n\" +\n",
    "    \"\\n\".join([f\"{col}: {row[col]}\" for col in df.columns if col != 'rag_summary' and col != 'embeddings']) +\n",
    "    \"\\nSource: Structured Carbon Dataset\"\n",
    "), axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b098249-1b68-437d-b343-6db5fab619eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rag_summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14e734-99e6-40d7-ab94-60ee54c910d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news['rag_summary'] = df_news.apply(lambda row: (\n",
    "    \"[TYPE: NEWS ARTICLE]\\n\"\n",
    "    \"Document: Climate & Emissions News\\n\"\n",
    "    f\"Title: {row['title']}\\n\"\n",
    "    f\"Description: {row['description']}\\n\"\n",
    "    f\"Source: {row['source']}\\n\"\n",
    "    f\"Country: {row['country']}\\n\"\n",
    "    f\"Published At: {row['pubDate']}\\n\"\n",
    "    f\"Link: {row['link']}\\n\"\n",
    "    \"Source: External News Feed\"\n",
    "), axis=1)\n",
    "\n",
    "df_news\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3993c6-a0df-45c7-b020-d352aacf9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news['rag_summary'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b53d816-2ddd-4545-a543-e4516bc609a2",
   "metadata": {},
   "source": [
    "### Turn RAG summary into sentence embeddings, and merge the RAG summary and the sentence embeddings from both dataset into a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1768f18c-cdbb-4ef0-a9c8-8e8f1161c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Step 2: Load SentenceTransformer Model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Step 3: Generate Embeddings\n",
    "carbondata_embeddings = embedder.encode(df[\"rag_summary\"].tolist(), show_progress_bar=True)\n",
    "news_embeddings = embedder.encode(df_news[\"rag_summary\"].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Step 4: Store embeddings in a new column\n",
    "df[\"embeddings\"] = carbondata_embeddings.tolist()\n",
    "df_news[\"embeddings\"] = news_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888892c7-a399-4fb8-9002-4ad8aeb726cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge RAG summary and embeddings\n",
    "df_combined = pd.concat([\n",
    "    df[['rag_summary', 'embeddings']],        # your carbon data\n",
    "    df_news[['rag_summary', 'embeddings']]    # your news data\n",
    "], ignore_index=True)\n",
    "\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc051459-9f2b-4820-8138-95c6388e287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2971ad-f918-42b6-85f2-d0709069459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('prepared_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1642b34-4656-49ad-9488-f589bedca95f",
   "metadata": {},
   "source": [
    "### Upload the Combined Data to Cloud Database (now use duckdb for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6724b0f6-2832-40b2-8391-862388ff1a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# 1. Connect to (or create) the DuckDB database\n",
    "con = duckdb.connect(\"combined_emission_data.duckdb\")\n",
    "\n",
    "# 2. Register the Pandas DataFrame as a temporary view\n",
    "con.register(\"df_combined_view\", df_combined)\n",
    "\n",
    "# 3. Create a permanent table from that view\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE combined_data AS\n",
    "    SELECT * FROM df_combined_view\n",
    "\"\"\")\n",
    "\n",
    "con.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
